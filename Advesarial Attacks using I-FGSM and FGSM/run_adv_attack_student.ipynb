{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adv_attack_student import AdversialAttacker\n",
    "from adv_attack_student import generate_experiment\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create experiment case\n",
    "x = generate_experiment(method='FGSM')\n",
    "\n",
    "input_img    = x['img']\n",
    "input_tensor = x['inp']\n",
    "attacker     = x['attacker']\n",
    "model        = x['mdl']\n",
    "un_norm      = x['un_norm']\n",
    "classnames   = x['classnames']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the classifier model\n",
    "out_pred, scores = attacker.get_pred_label(model, input_tensor, ret_out_scores=True, ret_out_pred=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the classfier scores\n",
    "print( \"current prediction: %d (%s)\\n\" % ( int(out_pred), classnames[int(out_pred)] ) )\n",
    "\n",
    "top_scores, top_indices = scores.topk(5)\n",
    "print( \"current top-5 scores:\" )\n",
    "for ss, ii in zip( top_scores.numpy().ravel(), top_indices.numpy().ravel() ):\n",
    "    print( ' - %d (%s): %.4f' % ( int(ii), classnames[int(ii)], ss ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the image before attacking\n",
    "input_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's attack\n",
    "\n",
    "# untargeted setting\n",
    "inp_adv = attacker.perturb_untargeted(model, input_tensor, eps=1e-1)\n",
    "\n",
    "# # targeted setting\n",
    "# target_label = 7\n",
    "# inp_adv = attacker.perturb_targeted(model, input_tensor, targ_label=[target_label], eps=0.03)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the image after attacking\n",
    "img_adv = un_norm(inp_adv.squeeze(0))\n",
    "img_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the perturbation \"directly\"\n",
    "def diff_img(img1, img2,scale=1):\n",
    "    return Image.fromarray(\n",
    "        scale * np.abs(     \n",
    "            np.array(img1).astype('float') - np.array(img2).astype('float')\n",
    "        ).astype(np.uint8)\n",
    "    )\n",
    "\n",
    "img_diff = diff_img(img_adv, un_norm(input_tensor.squeeze(0)), scale=1) # you can play with scale to amplify the signals\n",
    "img_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the perturbation, by heatmap\n",
    "\n",
    "# note: the image pixel values are in range 0-255\n",
    "img_orig_np = np.array(un_norm(input_tensor.squeeze(0))).astype('float')\n",
    "img_adv_np  = np.array(img_adv).astype('float')\n",
    "img_diff_np = np.abs( img_adv_np - img_orig_np ).sum(axis=2)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img_diff_np, cmap='jet', vmin=0, vmax=np.array(img_diff_np).max());\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run classifier again for the attacked image\n",
    "attacked_pred, attacked_score = attacker.get_pred_label(model, inp_adv, ret_out_scores=True, ret_out_pred=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check scores\n",
    "print( \"current prediction: %d (%s)\\n\" % ( int(attacked_pred), classnames[int(attacked_pred)] ) )\n",
    "\n",
    "top_attacked_scores, top_attacked_indices = attacked_score.topk(5)\n",
    "print( \"current top-5 scores:\" )\n",
    "for ss, ii in zip( top_attacked_scores.numpy().ravel(), top_attacked_indices.numpy().ravel() ):\n",
    "    print( ' - %d (%s): %.4f' % ( int(ii), classnames[int(ii)], ss ) )\n",
    "\n",
    "print(\"\\nDid we fooled the classifier?\")\n",
    "if int(attacked_pred) != int(out_pred):\n",
    "    print(' - Yes!')\n",
    "else:\n",
    "    print(' - Nah.')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
